{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAPIDS Taxi demo on AzureML\n",
    "\n",
    "References:\n",
    " - https://github.com/drabastomek/MLADS_RAPIDS/blob/master/notebook/1_pandasVsRapids_ETL.ipynb\n",
    " - https://github.com/danielsc/azureml-and-dask/blob/master/LoadDataFromDatastore.ipynb\n",
    " - https://github.com/danielsc/azureml-and-dask/blob/master/StartDask.ipynb\n",
    " - https://medium.com/@santiagof/the-holy-bible-of-azure-machine-learning-service-a-work-through-for-the-believer-part-1-4fe8f9853492\n",
    " - https://github.com/Azure/MachineLearningNotebooks/blob/master/how-to-use-azureml/training-with-deep-learning/distributed-tensorflow-with-horovod/distributed-tensorflow-with-horovod.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "\n",
    "from azureml.core import Workspace, Experiment, Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "from azureml.data.data_reference import DataReference\n",
    "from azureml.core.runconfig import RunConfiguration, MpiConfiguration\n",
    "from azureml.core import ScriptRunConfig\n",
    "from azureml.train.estimator import Estimator\n",
    "from azureml.exceptions import ComputeTargetException  \n",
    "from azureml.widgets import RunDetails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.json', 'r') as f:\n",
    "    config = json.loads(f.read())\n",
    "    \n",
    "subscription_id = config[\"subscription_id\"]\n",
    "resource_group = config[\"resource_group\"]\n",
    "workspace_name = config[\"workspace_name\"]\n",
    "gpu_cluster_name = \"kdd-gpu-cluster\"\n",
    "\n",
    "ws = Workspace(workspace_name=workspace_name, subscription_id=subscription_id, resource_group=resource_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing compute target\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    gpu_cluster = ComputeTarget(workspace=ws, name=gpu_cluster_name)\n",
    "    print('Found existing compute target')\n",
    "    \n",
    "except ComputeTargetException:\n",
    "    print(\"Creating new cluster\")\n",
    "\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(\n",
    "        vm_size=\"Standard_ND12s\", \n",
    "        min_nodes=1, \n",
    "        max_nodes=2,\n",
    "        idle_seconds_before_scaledown=120,\n",
    "        admin_username='dask',\n",
    "        admin_user_password='dask',\n",
    "        admin_user_ssh_key=open(os.path.expanduser('~/.ssh/id_rsa.pub')).read().strip()\n",
    "    )\n",
    "    gpu_cluster = ComputeTarget.create(ws, gpu_cluster_name, provisioning_config)\n",
    "\n",
    "    print(\"waiting for nodes\")\n",
    "    gpu_cluster.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Downloading NYC Taxi dataset... \n",
      "yellow_tripdata_2015-01.csv already exists\n",
      "yellow_tripdata_2015-02.csv already exists\n",
      "yellow_tripdata_2015-03.csv already exists\n",
      "yellow_tripdata_2015-04.csv already exists\n",
      "yellow_tripdata_2015-05.csv already exists\n",
      "yellow_tripdata_2015-06.csv already exists\n",
      "yellow_tripdata_2015-07.csv already exists\n",
      "yellow_tripdata_2015-08.csv already exists\n",
      "yellow_tripdata_2015-09.csv already exists\n",
      "yellow_tripdata_2015-10.csv already exists\n",
      "yellow_tripdata_2015-11.csv already exists\n",
      "yellow_tripdata_2015-12.csv already exists\n",
      "Finished downloads\n",
      "- Uploading taxi data... \n",
      "Uploading an estimated of 12 files\n",
      "Target already exists. Skipping upload for nyctaxi/yellow_tripdata_2015-02.csv\n",
      "Target already exists. Skipping upload for nyctaxi/yellow_tripdata_2015-01.csv\n",
      "Target already exists. Skipping upload for nyctaxi/yellow_tripdata_2015-06.csv\n",
      "Target already exists. Skipping upload for nyctaxi/yellow_tripdata_2015-05.csv\n",
      "Target already exists. Skipping upload for nyctaxi/yellow_tripdata_2015-11.csv\n",
      "Target already exists. Skipping upload for nyctaxi/yellow_tripdata_2015-03.csv\n",
      "Target already exists. Skipping upload for nyctaxi/yellow_tripdata_2015-09.csv\n",
      "Target already exists. Skipping upload for nyctaxi/yellow_tripdata_2015-08.csv\n",
      "Target already exists. Skipping upload for nyctaxi/yellow_tripdata_2015-12.csv\n",
      "Target already exists. Skipping upload for nyctaxi/yellow_tripdata_2015-10.csv\n",
      "Target already exists. Skipping upload for nyctaxi/yellow_tripdata_2015-04.csv\n",
      "Target already exists. Skipping upload for nyctaxi/yellow_tripdata_2015-07.csv\n",
      "Uploaded 0 files\n",
      "** Finished! **\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "data_dir = os.path.abspath(os.path.join(cwd, 'data'))\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "taxidir = os.path.join(data_dir, 'nyctaxi')\n",
    "if not os.path.exists(taxidir):\n",
    "    os.makedirs(taxidir)\n",
    "\n",
    "print(\"- Downloading NYC Taxi dataset... \", flush=True)\n",
    "for i in range(1, 13):\n",
    "    filename = \"yellow_tripdata_2015-{month:02d}.csv\".format(month=i)\n",
    "    local_path = os.path.join(taxidir, filename)\n",
    "    if not os.path.exists(local_path):\n",
    "        url = \"http://dask-data.s3.amazonaws.com/nyc-taxi/2015/\" + filename\n",
    "        urllib.request.urlretrieve(url, local_path)\n",
    "        print(\"Downloaded \" + filename, flush=True)\n",
    "    else:\n",
    "        print(filename + \" already exists\", flush=True)\n",
    "print(\"Finished downloads\", flush=True)\n",
    "\n",
    "    \n",
    "print(\"- Uploading taxi data... \")\n",
    "ws = Workspace.from_config()\n",
    "ds = ws.get_default_datastore()\n",
    "\n",
    "ds.upload(src_dir=taxidir,\n",
    "          target_path='nyctaxi',\n",
    "          show_progress=True)\n",
    "\n",
    "print(\"** Finished! **\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run dask cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpi_config = MpiConfiguration()\n",
    "mpi_config.process_count_per_node = 2\n",
    "\n",
    "est = Estimator(source_directory='./dask',\n",
    "                compute_target=gpu_cluster,\n",
    "                entry_script='startDask.py',\n",
    "                script_params={\n",
    "                    '--data': ws.get_default_datastore(),\n",
    "                    '--gpus': str(2),  # The number of GPUs available on each node\n",
    "                },\n",
    "                node_count=2,\n",
    "                use_gpu=True,\n",
    "                distributed_training=mpi_config,\n",
    "                conda_dependencies_file='environment.yml', \n",
    "               )\n",
    "\n",
    "run = Experiment(ws, 'conda-dask-test').submit(est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "waiting for scheduler node's ip\n",
      "waiting for scheduler node's ip\n",
      "waiting for scheduler node's ip\n",
      "waiting for scheduler node's ip\n",
      "waiting for scheduler node's ip\n",
      "waiting for scheduler node's ip\n",
      "waiting for scheduler node's ip\n",
      "waiting for scheduler node's ip\n",
      "waiting for scheduler node's ip\n",
      "waiting for scheduler node's ip\n",
      "waiting for scheduler node's ip\n",
      "waiting for scheduler node's ip\n",
      "waiting for scheduler node's ip\n",
      "waiting for scheduler node's ip\n",
      "waiting for scheduler node's ip\n",
      "waiting for scheduler node's ip\n",
      "waiting for scheduler node's ip\n",
      "waiting for scheduler node's ip\n",
      "waiting for scheduler node's ip\n",
      "waiting for scheduler node's ip\n",
      "waiting for scheduler node's ip\n",
      "waiting for scheduler node's ip\n",
      "waiting for scheduler node's ip\n",
      "waiting for scheduler node's ip\n",
      "waiting for scheduler node's ip\n",
      "waiting for scheduler node's ip\n",
      "waiting for scheduler node's ip\n",
      "waiting for scheduler node's ip\n",
      "waiting for scheduler node's ip\n",
      "waiting for scheduler node's ip\n",
      "waiting for scheduler node's ip\n",
      "waiting for scheduler node's ip\n",
      "waiting for scheduler node's ip\n",
      "waiting for scheduler node's ip\n",
      "waiting for scheduler node's ip\n",
      "waiting for scheduler node's ip\n",
      "waiting for scheduler node's ip\n",
      "waiting for scheduler node's ip\n",
      "waiting for scheduler node's ip\n",
      "waiting for scheduler node's ip\n",
      "waiting for scheduler node's ip\n",
      "waiting for scheduler node's ip\n",
      "waiting for scheduler node's ip\n",
      "waiting for scheduler node's ip\n",
      "waiting for scheduler node's ip\n",
      "waiting for scheduler node's ip\n",
      "waiting for scheduler node's ip\n",
      "waiting for scheduler node's ip\n",
      "Headnode has IP: 10.0.0.4\n"
     ]
    }
   ],
   "source": [
    "while not 'headnode' in run.get_metrics():\n",
    "    print(\"waiting for scheduler node's ip\")\n",
    "    time.sleep(30)\n",
    "\n",
    "headnode = run.get_metrics()['headnode']\n",
    "print('Headnode has IP:', headnode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "âš  *TODO: Get in line SSH port forwarding working.*\n",
    "\n",
    "For now open a terminal and run \n",
    "\n",
    "`ssh -N -L 8787:<headnode IP>:8787 -L 8786:<headnode IP>:8786 dask@<Compute VM IP> -p <Compute VM Port>`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import asyncio\n",
    "# import asyncssh\n",
    "\n",
    "# async def forawrd_scheduler_port():\n",
    "#     async with asyncssh.connect('51.105.168.166', username='dask', port=50001, known_hosts=None) as conn:  # TODO Get IP and port programatically\n",
    "#         listener_dash = await conn.forward_local_port('', 8787, headnode, 8787)\n",
    "#         listener_server = await conn.forward_local_port('', 8786, headnode, 8786)\n",
    "#         await asyncio.gather(listener_dash.wait_closed(), listener_server.wait_closed())\n",
    "        \n",
    "# port_forward_future = asyncio.create_task(forawrd_scheduler_port())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://localhost:8786\n",
       "  <li><b>Dashboard: </b><a href='http://localhost:8787/status' target='_blank'>http://localhost:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>4</li>\n",
       "  <li><b>Cores: </b>4</li>\n",
       "  <li><b>Memory: </b>78.89 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://10.0.0.4:8786' processes=4 cores=4>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import distributed\n",
    "client = distributed.Client('tcp://localhost:8786')\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taxi example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask_cudf\n",
    "import dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def remote_load(path):\n",
    "     return dask_cudf.read_csv(path)\n",
    "\n",
    "gdf = remote_load(os.path.join(run.get_metrics()['data'], 'nyctaxi/*.csv')).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>RateCodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=91</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>int64</td>\n",
       "      <td>datetime64[ms]</td>\n",
       "      <td>datetime64[ms]</td>\n",
       "      <td>int64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>int64</td>\n",
       "      <td>object</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>int64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: read-csv, 91 tasks</div>"
      ],
      "text/plain": [
       "<dask_cudf.DataFrame | 91 tasks | 91 npartitions>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e51a110650d49a482bb550e7730aa3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = gdf.passenger_count.sum().persist()\n",
    "distributed.progress(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "245566747"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e80bcfa838249faab258e0d286b2d20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = gdf.groupby(gdf.passenger_count).trip_distance.mean().persist()\n",
    "distributed.progress(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9    1.800759e-04\n",
       "3    9.650539e-02\n",
       "6    7.298475e-01\n",
       "1    2.016156e+02\n",
       "2    1.033339e+06\n",
       "5    1.344814e+05\n",
       "7    1.932367e-02\n",
       "8    2.347478e-04\n",
       "0    5.509554e+02\n",
       "4    3.635078e+00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.compute().to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Array example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15236e38dd424afdab2a528a55daa9d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dask.array as da\n",
    "arr = da.random.random((100_000, 100_00), chunks=(10_000, 1000)).persist()\n",
    "distributed.progress(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7ebceb4197140819890d944a67022d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m = arr.mean().persist()\n",
    "distributed.progress(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5000059014539492"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up Dask cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.cancel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete AzureML cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.client - ERROR - Failed to reconnect to scheduler after 10.00 seconds, closing client\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted\n"
     ]
    }
   ],
   "source": [
    "gpu_cluster.delete()\n",
    "try:\n",
    "    gpu_cluster.wait_for_completion(show_output=True)\n",
    "except ComputeTargetException:\n",
    "    print('Deleted')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
